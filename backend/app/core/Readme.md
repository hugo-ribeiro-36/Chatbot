# ğŸ§  Chatbot Application (FastAPI + React)

This is a full-stack AI chatbot system that integrates OpenAIâ€™s powerful models with local knowledge search and file-based retrieval. It features real-time streaming responses, version-based A/B testing, vector-based memory, web search, and user feedback collection.

---

## ğŸ“ Project Structure

```
chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/                 # Core logic: embedding search, prompts, LLM engine
â”‚   â”‚   â”œâ”€â”€ db/                   # Database models and session
â”‚   â”‚   â”œâ”€â”€ routes/               # FastAPI routes (chat, upload, feedback, etc.)
â”‚   â”‚   â”œâ”€â”€ schemas/              # Pydantic schemas for request/response validation
â”‚   â”‚   â””â”€â”€ main.py               # FastAPI app entry point
â”‚   â”œâ”€â”€ tests/                    # Unit tests for API endpoints
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env                      # API keys and environment variables (not committed)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/           # Chat UI, feedback, file upload
â”‚   â”‚   â”œâ”€â”€ pages/                # Main chat interface
â”‚   â”‚   â”œâ”€â”€ utils/                # SSE streaming handler
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
```

---

## ğŸ’¡ Features

- ğŸ”„ **Streaming responses** with Server-Sent Events (SSE)
- ğŸ§  **Vector-based search** using ChromaDB and OpenAI embeddings
- ğŸ“„ **File upload** support with OpenAI Assistants API (retrieval tool)
- ğŸŒ **Web search** via GPT with web tool access
- ğŸ§ª **A/B testing** of different system prompts
- ğŸ“Š **Feedback collection**: thumbs up/down + optional comment
- ğŸ’¬ **Conversation history and switcher** to continue old chats

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/chatbot.git
cd chatbot
```

---

### 2. Backend Setup (FastAPI)

#### âœ… Environment Variables

Create a `.env` file inside `backend/` with the following:

```env
OPENAI_API_KEY=sk-...
CHROMA_PATH=./chromadb
DATABASE_URL=sqlite:///./chatbot.db
```

#### ğŸ›  Install and Run

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or venv\\Scripts\\activate on Windows
pip install -r requirements.txt
uvicorn app.main:app --reload
```

Backend runs at: [http://localhost:8000](http://localhost:8000)

---

### 3. Frontend Setup (React + Vite)

```bash
cd frontend
npm install
npm run dev
```

Frontend runs at: [http://localhost:5173](http://localhost:5173)

---

## ğŸ§ª Running Tests

From the backend root:

```bash
python -m unittest discover tests
```

---

## ğŸ§± Architectural Highlights

- **FastAPI** serves as a lightweight backend for handling chat, file uploads, feedback, and versioned prompt logic.
- **React** provides a responsive chat interface with real-time streaming and feedback controls.
- **ChromaDB** powers the vector store for semantic search on custom knowledge documents.
- **OpenAI Assistants API** allows file-based retrieval and long-context Q&A.
- **A/B Testing** logic assigns system prompts randomly per conversation and tracks performance.

---

## ğŸ” API Keys & Security

Be sure to keep your `.env` file safe. Never commit it to version control. If deploying, use secrets management.

---

## ğŸ§© Next Steps

- Add authentication (optional)
- Store feedback analytics in a dashboard
- Deploy with Docker or cloud

---

## ğŸ›  Built With

- FastAPI
- React + Vite
- ChromaDB
- OpenAI API (GPT-4, GPT-3.5)
- SQLite

---

## ğŸ“¬ Feedback

Pull requests and issues are welcome!
